# pywatts & sktime tech discussion, 29 April 2022

###### tags: `sktime`, `pywatts`

**:calendar:** 2022, April 29

## :wave: Attendees

- [name=Lovkush Agarwal]
- [name=Stefan Meisenbacher]
- [name=Franz Kiraly]
- [name=Benedikt Heidrich]
- [name=Kaleb Phipps]
- [name=Martin Walter]


## Roles
* notetaker - Franz
* moderator - Kaleb

## :clipboard: Agenda

3. identifying key design decision points (no decisions yet)
4. concretizing consequence in implementation

**Milestone 2: options laid out**

5. decision making - options
6. tickets & actions

**Milestone 3: complete plan**


## Actions from last meeting

* sktime to go back to CC, report on discussion & proposed decisions in high-level points, for decision in Apr 19 meeting.
    * accepted by CC
* both pywatts, sktime, continue meeting series, starting Apr 22
    * "consequences" need working out for detail interface items
    * continue thinking about implementation



## :pencil: Notes
in collab area below

## actions

action all (individual or group-wise)
design proposals for `__call__` dunder and associated classes
try send by May 5 EoB, pre-read for May 6

action FK: open issue on sktime to collect designs (but don't put design directly in issue before May 5)


## collaboration area





## from Apr 8

Main design decision points

### architectural, high-level

* relation of sktime, pywatts base APIs - target state
    * option 1: joint base API
    * option 2: separate base API, adaptors
    * option 3: separate base API, no adaptors
    * FK opinion: I think we need option 1. We decided this last time, I think, or else we can't talk about the other points productively.
    * KP opinion: yep, agree with Franz.

sktime: FK, MW agree, preferably option 1 - for decision at CC
pywatts: all agree, preferably option 1

* nature of joint base API (needed as dev basis and for interoperability). Which base class interface to adopt in the end?
    * explanation: base API excludes dunder topic, excluding pipeline logic
    * option 1: sktime
    * option 2: pywatts
    * option 3: develop new or synthesis
    * analysis of alternatives: option 1, sktime, seems most mature, least work needed. pywatts does not have "type specific base classes". sktime has large user base and testing framework dependent on its interface, any change to that would cause major disruption
    * FK opinion: should be option 1, anything else seems like a no-go for sktime and large user base
    * BH opinion: depends *where* we change sth, e.g., whether changes are downwards compatible, additional, or change loci of high dependency
    * KP opinion: agree that changes for a large user base for sktime will be difficult. However, additions that can be ignored downstream but enable functionality for pyWATTS should perhaps be considered.

sktime: FK, MW agree, preferably option 1; as said, dunder/pipeline discussed separately. For decision.
pywatts: all agree, preferably option 1

* package structure
    * option 1: sktime + pywatts
        * implication: 2 packages, separately maintained in a joint ecosystem. As-is state, plus likely some integrative moves.
        * MW thinks there is problematic implication also in "option 1 first then other option": if we go for option 1, would waste time
        * FK: but anything except option 1 at the start seems require more substantial effort. BH: agree, option 1 and then possibly sth else is the agile approach.
    * option 2: one merged package
        * implication: "package merge". FK: this needs to start at a merge design & requirements effort
    * option 3: sktime core + sktime modules + pywatts
        * implication: "ecosystem refactor". FK: also starts at the design board
    * FK opinion: I would prefer option 1 short-term, option 3 long-term, similar to the mlr ecosystem. Option 2 is "bad" imo since it creates a monster package and it moves *away* from modularity. Moving *towards* modularity is a design desideratum.
    * BH opinion: I aggree to Franz.
    * SM comment: How to handle testing in options 1, 2, and 3?
        * FK: tests from sktime can be extended and imported
        * FK: what about pywatts test?
    * KP opinion: I also think that option 3 long-term and option 1 short-term is the best option.
    * MW prefers option 2, right away
        * FK: why is preferable to option 1 then option 2?
        * MW: saving effort in refactor through redesign first
    * MW is also ok with option 1, due to more agile start. Can revisit 2 vs 3 for long-term at the design board.

sktime: FK, MW option 1, for decision

pywatts: all agree, preferably option 1

#### class interface level

* `__call__` interface point of pywatts, what to do about this.
    * option 0a: call dunder has to be implemented in sktime modules, additional to existing pipelines = adding to base interface. The same as 1a or 1b
    * option 0b: replacing ForecastingPipeline in sktime by call dunder & adding to base interface
        * clarification BH: this as meant as replacing FP by pywatts pipeline, but that is a separate decision point, could "coexist"
        * FK: current * dunder does similar thing, called from base class (transformer etc), constructs specialized pipeline class. But current sktime user interface weighs the explicit construction option more heavily in its self-presentation.
        * variant of option 1 where, in addition, ForecastingPipeline gets replaced by the pywatts pipeline
    * KP comment: this point is already discussed above.

    * option 1: sktime adopt pywatts or with minor changes
    * option 1b: integration in sktime base interface, but only if pywatts package/module is loaded or enabled
    * option 2: pywatts as decorator or mixin for sktime
    * option 3: pywatts wraps sktime, adaptor pattern, user has to wrap
    * option 4: sktime provides adaptor, user has to use
    * option 5: stays in pywatts, sktime does nothing
    * FK opinion: I would go with option 1, I think this is well thought out and elegant. Will be familiar to keras users. We need to think how it works together with dunders and other magic methods, but that seems like a solvable problem.
    * MW opinion: concern on `__call__` method, design departure from scikit-learn. Consequence would be major design departure from sktime.
        * FK: yes, it is closer to keras philosophy
        * GB: agree, would like to avoid integrating it into sktime
        * BH: agrees, but thinks synthesis of scikit-learn and keras designs could lead to improvements, both will be familiar to generic data science community members. Departure but not in opposition.
        * GB: seems like design complication, may be design overload. Simplicity of design is a design desideratum, and it will reduce simplicity.
        * SM: can we do this that you only get this only if you load pywatts? I.e., only then, the `__call__` dunder is added, and it is a user choice.
    * MW opinion: `__call__` is a specific design choice, not necessarily needed for network/graphical pipeline. Is against. We may want to go back to the design table and tease apart the decision on network pipeline vs specific implementation of network pipeline.
    * MW: could start with option 5 and drill down on the topic in further design discussions, consequences/implications are not fully clear yet
        * main concern is move away from sklearn philosophy
    * BH, option 6: sktime to adopt pywatts `__call__`, but as a method of specific name, e.g., `pipeline` or `chain` etc
    * MW: are there graphical pipelines for sklearn?

* status of the "module" formalism in pywatts
    * option 1: remove/abandon
    * option 2: massage into BaseObject formalism
    * option 3: separate/parallel existence
    * analysis: "modules" are to large extent estimators, but they do not map 1:1 since it could include statistical analysis or plotting of results, which sktime does not abstract. It may be desirable to have abstractions for such "reporting" workflow steps.
    * FK opinion: I would prefer option 3 short-term, move to option 2 mid-term (largely based on pywatts design). sktime had similar design studies around benchmarking, reporting, e.g., the statistical tests module and reporting functionality which got abandoned. This may be a larger piece of work though.
    * BH opinion: I would prefer option 3 for now but in future we should aim to realise point 2. Option 3 is easy to realise. Option 2 would unify the API. However, for option 2, we need to think which BaseObjects and how they are defined (Task dependent or output dependent)
    * KP opinion: I think option 2 is definitely a good long term target, but option 3 is probably simpler to implement for now. 

* BH: how input for module is handled when passed to estimator, e.g., mapping on forecasting horizon, handling of AR forecasts (as opposed to "reduced" forecasts where you have X, y and predict y from X)
    * option 1: pywatts wraps sktime
    * option 2: redesign of pywatts "module" design
    * FK, option 3: adoption of sktime would allow handling that easily via fh?
    * BH, option 4: allow usage of ForecastingHorizon also in pyWATTS. Extend the step functionality in pyWATTS to enable AR strategies etc. Probably similiar to option 2.
    * BH opinion: I think we have to elaborate more on the different options. Currently, I am not able to decide which option I prefer.

* base class interface: handling and specification of input data formats
    * option 1: only xarray
    * option 2: sktime data formats, sktime native interface
    * FK, option 3: sktime data formats plus xarray, using sktime datatypes module (easily extensible :smiley: )
    * option 4: custom data format for allowing different kind of passed data. E.g., an object identifying if the data is a time series or only a snippet (might be interessting for motif discovery)
        * FK: that's the "adaptor/strategy" pattern, right? Yes
    * option 5: sth else
    * BH opinion: Depending on the option about the BaseObject, option 4 might be useful for checking if the output and input of consecutive BaseObject match. However, I suppose that the easiest way is option 3.

* How to handle inputs from multiple sources a provided to a sktime module (e.g., calendar information and time series values itself)
    * FK comment: this is about "network pipeline" or "graph pipeline" design, right? `__call__` allows to handle this nicely. Sktime does not have this.
    * BH, Option 1: pyWATTS has to concat these data in a way that sktime estimators can handle them. 
    * BH, Option 2: This is not allowed for sktime estimators
    * BH, Option 3: skTime estimators allow it if and when useful.
    * MW: I have an open PR: https://github.com/alan-turing-institute/sktime/pull/1727

* How to save and load pipelines to and from folders?
    * KP comment: having the ability to save and load pipelines (including parameters) is an important aspect for the use of pipelines. Therefore it is definitely a feature that should survive through any changes. We are not sure how easy this is to integrate with sktime.
    * SM option 1: pyWATTS ensures that sktime estimators can be loaded and saved
    * SM option 2: sktime implements save and load functionality
        * FK: yes, could be some default "persistence" interface
    * FK: whatÂ´s wrong with pickle? is that a viable option 3?
        * BM: keras models cannot be pickled, may pose issues


## Purpose of call dunder (requirements):

Benedikt thoughts:

* Define the inputs of the modules
* Enable controlling of pipeline steps. (E.g., training/only transforming. Specifying callbacks for visualising, ..)
* Should the callback functionality be used for plotting the results of a module, etc...
* Introduce different data types for different kinds of transformers (e.g. Motif Discover Transformer would provide a set of snippets, a Regression would provide a time series, etc.)?


Stefans thoughts:
* returns `StepInformation` that can be used as input for the next step in the pipeline (similar to the keras functional API)


FK thoughts:

* creation of graph pipeline object
* should work with transformers, forecasters, classifiers
* working with "workflow elements" like plots, tests? may have to treat that separately?
* possibly: single class for graph objects? (returned)
    * example: ForecastingPipeline, `__mul__` dunder returns `ForecastingPipeline`
* signature - specification of graph pipeline, reference to "parent" DAG elements, connection specifiers, ?callbacks
* should be able to invoke with multiple estimators/modules as inputs
* named references to variable names and variable subsets in composition? (maybe with some functionality where variable are renamed) alternatively, could be a "variable subset" or "variable rename" transformer and need not be arg of `__call__`


imo, there needs to be a `GraphPipeline` class or similar, `__call__` returns an instance of it, which has references

`GraphPipeline` could be polymorphic, or scitype (forecaster, classifier, etc) specific


```python
    my_pywatts_network = sthsth
    est_plus_layer = est(my_pywatts_network, stuff)
```
where `my_pywatts_network` is a `GraphPipeline`?
(in `pywatts` it is a step-information, not an estimator)

might be simple change, `GraphPipeline` (executable, estimator-like) replacing `StepInformation` (= "builder" object)

* instead of the `__call__` dunder we could also use the `<<` or `>>` dunder? But that doesn't allow params of composition, so perhaps not a good idea

* probably we want to keep `pywatts` pipelining sufficiently general so it is not necessarily only `sktime` compatible! Suggests layer separation between `GraphPipeline` and `StepInformation`?



# API Ideas:
The call dunder for each API needs as arguments:
* inputs (previous modules) -> List, Dict, or kwargs
* targets (previous moduls) -> List, Dict, or kwargs
* Execution Control parameter: Should the step be trained or only transformed or always trained. Which transform method should be executed (inverse, normal, probabilistic)
* Online Based Features as refit conditions to determine when a module should be refitted. Additionally, online learning/execution based parameters would be lag, batch, etc.
* Callbacks: Possibility to work directly on the output of a module. Could also be realised by a special type of module instead of callbacks.


##  Graphpipeline without seeing Pipeline Objects
Based on the idea of Franz to replace the StepInformation: 

```python=
interpolated = LinearInterpolation()(x=Column("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)

regressor1.train(data)
regressor2.train(data)

collected_results = Collector()(x1=regressor1, x2=regressor2)
colelcted_results.train()


outliers.train(data)
```

### Idea:
Try to construct a pipeline objects without the need of explicitly creating a pipeline. I.e., the pipeline object returned by the call dunder describes the pipeline up to the module added by the specifica call dunder. To realise such an API the call dunder has to:
* return a Pipeline Object or something similar. I.e. the StepInformation has to be enhanced. And it must be possible to call train, test, etc directly on the new StepInformation.




### Possible Challenges:
* How are global parameters set?
  * FileManager
  * Online/Batch Execution Flag, ...
* Each module or returned Pipeline Object has to track all needed inputs and the corresponding name of the column in the dataset. I.e., each returned PipelineObjects needs pointers to it's predessors and the input steps.
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.
* Need to specify the input columns of the first module/estimator (`x=Column("bar")`)
* Where should storage paths be determined (Currently in the initialisation of the pipeline.)
* Are Pipelines with multiple output possible? Probably only with Dummy (`Collector()`) which collects multiple modules/estimators


### Advantages:
* The user has not to care about creating a Pipeline. Because *Everything is a Pipeline*. Clean way to construct pipelines.

## Alternative: Extend Existing API

The current API works. However, a new can prettify it and the API has to be enhanced. The `StepInformation` is kept.


```python=
pre_processing_pipeline = Pipeline()
interpolated = LinearInterpolation()(x=pipeline("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)

estimator_pipeline = Pipeline()
regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


estimator_pipeline.train(data)

# can be applied elsewhere
pre_processing_pipeline.to_folder(path...)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.

### Advantage
* Multiple last modules/estimators are possible without collector steps or something similar

## Alternative: Full Keras API Style
Define Pipeline after the describing how the different steps are connected.


```python=
interpolated = LinearInterpolation()(x=Column("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


# Full Keras Style
pipeline = Pipeline(inputs=[interpolated], targets=[regressor1, regressor2, outlier])

pipeline.train(data)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.

### Drawback:
* If a last step is deleted the user has to adapt the line where the pipeline is created. Coding errors may arise here.

## Alternative: Pipeline without Step Information

Similar like the current API but instead of step information an estimator or Graphpipeline is returned.

```python=
pipeline = Pipeline()
interpolated = LinearInterpolation()(x=pipeline("bar"))
calendar = CalendarExtraction()(x=interpolated)
scaler = StandardScaler()
scaled = SKLearnWrapper(scaler)(x=interpolated)
outliers = SKLearnWrapper(LocalOutlierFactor())(x=scaled, calendar=calendar)


regressor1 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)
regressor2 = SklearnWrapper(LinearRegression)(x=scaled, calendar=calendar)


pipeline.train(data)


# Now this is possible
regressor1.transform(data)
```

### Challenges:
* Check if the output of the predecessor fits to the input of the added pipeline. E.g., if we have different modules/estimators like motif discovery, forecasting etc. their outputs differs. If it is allowed to combine different ones in one pipeline, we should check this before the execution of the pipeline.
* How are global parameters set for e.g. `regressor1.transform(data)`
  * FileManager
  * Online/Batch Execution Flag, ...
* Each module or returned Pipeline Object has to track all needed inputs and the corresponding name of the column in the dataset. I.e., each returned PipelineObjects needs pointers to it's predessors and the input steps.
* Where should storage paths be determined (Currently in the initialisation of the pipeline.) for `regressor1.transform(data)`


### Advantages:
* There is no step information and each object in the pipeline is fittable, i.e. we can directly call fit or transform for a regressor in the pipeline (as shown in example)

